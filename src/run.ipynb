{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torch_geometric transformers tokenizers"
      ],
      "metadata": {
        "id": "SDvow3Tfu2-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/co-citation-prediction/src"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dAY3buCujDs",
        "outputId": "aa21d4cc-df58-444f-978b-402afc3061bb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/co-citation-prediction/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "NNRyGTHkuflq"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from tokenizers import Tokenizer\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from data import EncoderDataset, GraphDataset, RegressionDataset\n",
        "from encoder import EncoderModel\n",
        "from graph import GraphModel\n",
        "from model import Model\n",
        "from regression import RegressionModel"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print (torch.cuda.is_available())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0jw8O4ww2b0",
        "outputId": "d8d9a3a8-b5da-4b2e-f199-8d8e4a13c268"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "__t_63Sqzyuw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "embeddings = None\n",
        "test = None\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "E8mnbphr0H-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tm0Vm_bouflv"
      },
      "outputs": [],
      "source": [
        "data_path = \"../data/data.feather\"\n",
        "tokenizer_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "encoder_dataset = EncoderDataset(data_path, tokenizer_name, device)\n",
        "encoder_loader = DataLoader(\n",
        "    encoder_dataset,\n",
        "    batch_size=64,\n",
        "    shuffle=False,\n",
        "    collate_fn=encoder_dataset.collate_fn\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBsATfEOuflv"
      },
      "outputs": [],
      "source": [
        "encoder_config = {\n",
        "  # \"architectures\": [\n",
        "  #   \"BertForMaskedLM\"\n",
        "  # ],\n",
        "  # \"attention_probs_dropout_prob\": 0.1,\n",
        "  # \"gradient_checkpointing\": False,\n",
        "  # \"hidden_act\": \"gelu\",\n",
        "  # \"hidden_dropout_prob\": 0.1,\n",
        "  # \"hidden_size\": 768,\n",
        "  # \"initializer_range\": 0.02,\n",
        "  # \"intermediate_size\": 3072,\n",
        "  # \"layer_norm_eps\": 1e-12,\n",
        "  # \"max_position_embeddings\": 512,\n",
        "  # \"model_type\": \"bert\",\n",
        "  # \"num_attention_heads\": 12,\n",
        "  # \"num_hidden_layers\": 12,\n",
        "  # \"pad_token_id\": 0,\n",
        "  # \"position_embedding_type\": \"absolute\",\n",
        "  # \"transformers_version\": \"4.6.0.dev0\",\n",
        "  # \"type_vocab_size\": 2,\n",
        "  # \"use_cache\": True,\n",
        "  # \"vocab_size\": 30522\n",
        "  \"_name_or_path\": \"nreimers/MiniLM-L6-H384-uncased\",\n",
        "  \"architectures\": [\n",
        "    \"BertModel\"\n",
        "  ],\n",
        "  \"attention_probs_dropout_prob\": 0.1,\n",
        "  \"gradient_checkpointing\": False,\n",
        "  \"hidden_act\": \"gelu\",\n",
        "  \"hidden_dropout_prob\": 0.1,\n",
        "  \"hidden_size\": 384,\n",
        "  \"initializer_range\": 0.02,\n",
        "  \"intermediate_size\": 1536,\n",
        "  \"layer_norm_eps\": 1e-12,\n",
        "  \"max_position_embeddings\": 512,\n",
        "  \"model_type\": \"bert\",\n",
        "  \"num_attention_heads\": 12,\n",
        "  \"num_hidden_layers\": 6,\n",
        "  \"pad_token_id\": 0,\n",
        "  \"position_embedding_type\": \"absolute\",\n",
        "  \"transformers_version\": \"4.8.2\",\n",
        "  \"type_vocab_size\": 2,\n",
        "  \"use_cache\": True,\n",
        "  \"vocab_size\": 30522\n",
        "}\n",
        "encoder_model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "encoder_model = EncoderModel(encoder_model_name, encoder_config).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "embeddings = np.empty((0, 384))\n",
        "import time\n",
        "for batch in encoder_loader:\n",
        "  # print(count)\n",
        "  # time.sleep(0.1)\n",
        "  batch = batch.T\n",
        "  infer = encoder_model(batch)\n",
        "  # print(infer)\n",
        "  embed = infer[0].to('cpu')\n",
        "  pool = infer[1].to('cpu')\n",
        "  add = embed[:, 0, :].cpu().tolist()\n",
        "  # test.append(embed[:, 0, :].cpu().tolist())\n",
        "  embeddings = np.concatenate((embeddings, add))\n",
        "  # print(test.get_device())\n",
        "  # embed_inpt = embed['last_hidden_state'][:, 0, :].cpu()\n",
        "  # test = torch.cat((test, embed[:, 0, :]), dim=0)\n",
        "  # test.append(embed_inpt)\n",
        "  # embed = None\n",
        "  # gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "  # if count == 1:\n",
        "  #   break\n",
        "  # count += 1"
      ],
      "metadata": {
        "id": "1PMod3B-wZiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSpbO35guflw"
      },
      "outputs": [],
      "source": [
        "graph_dataset = GraphDataset(embeddings, encoder_dataset.data)\n",
        "graph_loader = DataLoader(graph_dataset, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from itertools import combinations\n",
        "from torch_geometric.data import Dataset as GeoDataset\n",
        "from torch_geometric.data import Data as GeoData\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ],
      "metadata": {
        "id": "e-iE18D1oUHB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_index = encoder_dataset.data[[\"id\", \"references\"]].explode(\"references\").values.transpose()\n",
        "# lookupTable, indexed_dataSet = np.unique(edge_index.flatten(), return_inverse=True)"
      ],
      "metadata": {
        "id": "3gvt0F51otMs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paper_to_id = {}\n",
        "id_to_paper = {}\n",
        "graph_ei = np.empty(edge_index.shape)\n",
        "curr_id = 0\n",
        "for i in range(edge_index.shape[0]):\n",
        "  for j in range(edge_index.shape[1]):\n",
        "    papers = paper_to_id.keys()\n",
        "    paper = edge_index[i, j]\n",
        "    if paper not in papers:\n",
        "      paper_to_id[paper] = curr_id\n",
        "      id_to_paper[curr_id] = paper\n",
        "      curr_id += 1\n",
        "    graph_ei[i, j] = paper_to_id[paper]"
      ],
      "metadata": {
        "id": "06cAgcaIuT1t"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remaining_papers = max(id_to_paper.keys()) - embeddings.shape[0]\n",
        "average_embed = np.mean(embeddings, axis=0, keepdims=True)\n",
        "remaining_papers_embed = np.repeat(average_embed, remaining_papers, axis=0)\n",
        "final_embed = np.concatenate((embeddings, remaining_papers_embed), axis=0)"
      ],
      "metadata": {
        "id": "UeumfEXBuKgK"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = GeoData(x=final_embed, edge_index=graph_ei, is_directed=True)"
      ],
      "metadata": {
        "id": "yaslpWJNqkpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cQjOLMe1uflx"
      },
      "outputs": [],
      "source": [
        "graph_model = GraphModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDh6OtmTuflx"
      },
      "outputs": [],
      "source": [
        "regression_dataset = RegressionDataset(encoder_dataset.data, graph_model.embeddings)\n",
        "regression_loader = DataLoader(regression_dataset, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5_oVzXsuflx"
      },
      "outputs": [],
      "source": [
        "regression_model = RegressionModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_cc_9chufly"
      },
      "outputs": [],
      "source": [
        "model = Model(encoder_model, graph_model, regression_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCQoy7gJufly"
      },
      "outputs": [],
      "source": [
        "model.setup(encoder_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x8G4C_Qouflz"
      },
      "outputs": [],
      "source": [
        "model.train()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}